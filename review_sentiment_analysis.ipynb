{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e3ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095a15c8",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Sentimental analysis is the process of determining whether a piece of writing is positive, negative, or neutral. The below Algorithm is designed for use in Financial Texts. It consists of steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ce5b2",
   "metadata": {},
   "source": [
    "### Cleaning the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c00e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text so that we dont have unneccessary characters\n",
    "def clean_text(text):\n",
    "    \n",
    "    # retain words like don't\n",
    "    # text = re.sub(r'[a-z]+[''][a-z]')\n",
    "    \n",
    "    text = re.sub('the media could not be loaded.', '', text)\n",
    "    \n",
    "    # Include only alphabets\n",
    "    text = re.sub(r'[^a-zA-Z.]', ' ', text)\n",
    "    \n",
    "    # Remove Unicode characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove continuous spaces\n",
    "    text = re.sub(r'\\s\\s+', ' ', text)\n",
    "       \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02011ca",
   "metadata": {},
   "source": [
    "### Cleaning using Stop Words List\n",
    "\n",
    "The Stop Words Lists are used to clean the text so that Sentiment Analysis can be performed by excluding the words found in Stop Words List. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa50afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting stopwords\n",
    "\n",
    "stop_word_files = os.listdir('StopWords')\n",
    "\n",
    "STOPWORDS = []\n",
    "for file in stop_word_files:\n",
    "    path = os.path.join('StopWords', file)\n",
    "    \n",
    "    with open(path) as stopwords:\n",
    "        reader = stopwords.read()\n",
    "        STOPWORDS.extend(reader.split())\n",
    "STOPWORDS = pd.Series(STOPWORDS).apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4067c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stopwords\n",
    "\n",
    "def remove_stopwords(clean_text):\n",
    "    words = []\n",
    "    word_list = clean_text.split()\n",
    "    for word in word_list:\n",
    "        if word in STOPWORDS:\n",
    "            continue\n",
    "        words.append(word)\n",
    "        \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54034e80",
   "metadata": {},
   "source": [
    "### Creating a dictionary of Positive and Negative words\n",
    "The Master Dictionary is used for creating a dictionary of Positive and Negative words. We add only those words in the dictionary if they are not found in the Stop Words Lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ac1675",
   "metadata": {},
   "outputs": [],
   "source": [
    "MasterDictionary = {'Positive': [], 'Negative': []}\n",
    "\n",
    "with open('MasterDictionary\\\\negative-words.txt') as negative:\n",
    "    negative_words = negative.read().split()\n",
    "    for word in negative_words:\n",
    "        if word not in STOPWORDS:\n",
    "            MasterDictionary['Negative'].append(word)\n",
    "    \n",
    "with open('MasterDictionary\\\\positive-words.txt') as positive:\n",
    "    positive_words = positive.read().split()\n",
    "    for word in positive_words:\n",
    "        if word not in STOPWORDS:\n",
    "            MasterDictionary['Positive'].append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b219b1",
   "metadata": {},
   "source": [
    "### Extracting Derived variables\n",
    "We convert the text into a list of tokens using the nltk tokenize module and use these tokens to calculate the 4 variables described below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "530fd67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive Score\n",
    "def positive_score(words):\n",
    "    score = 0\n",
    "    for word in words:\n",
    "        if word in MasterDictionary['Positive']:\n",
    "            score += 1\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e551cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative Score\n",
    "\n",
    "def negative_score(words):\n",
    "    score = 0\n",
    "    for word in words:\n",
    "        if word in MasterDictionary['Negative']:\n",
    "            score += 1\n",
    "    \n",
    "    return score * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f96feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polarity Score\n",
    "\n",
    "def polarity_score(positive_score, negative_score):\n",
    "    score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "152d80d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjectivity Score\n",
    "\n",
    "def subjectivity_score(positive_score, negative_score, words):\n",
    "    score = (positive_score + negative_score) / ((len(words)) + 0.000001)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e93040",
   "metadata": {},
   "source": [
    "### Analysis of Readability\n",
    "Analysis of Readability is calculated using the Gunning Fox index formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d52eeda7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Average Sentence Length\n",
    "\n",
    "def avg_sent_len(text, words):\n",
    "    sentences = sent_tokenize(text)\n",
    "    length = len(words) / len(sentences)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cf0b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of Complex Words\n",
    "\n",
    "def percentage_of_comp_words(words):\n",
    "    return (complex_words(words) / len(words)) * 100\n",
    "\n",
    "# Fog Index\n",
    "\n",
    "def fog_index(avg_sent_length, percentage_of_comp_words):\n",
    "    return (0.4 * (avg_sent_length + percentage_of_comp_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba9cf9",
   "metadata": {},
   "source": [
    "### Complex Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03c36900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syllables(word):\n",
    "    vowels = 'aeiouy'\n",
    "    count = 0\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "        \n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index-1] not in vowels:\n",
    "            count += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb56571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_words(words):\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        syllable_counts = count_syllables(word)\n",
    "        if syllable_counts >=2:\n",
    "            count += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82721d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counts(words_):\n",
    "    count = 0\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for word in words_:\n",
    "        if word not in stop_words:\n",
    "            count += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bdfa26",
   "metadata": {},
   "source": [
    "### Syllable Count Per Word\n",
    "Counting the number of Syllables in each word of the text by counting the vowels present in each word. We also handle some exceptions like words ending with \"es\",\"ed\" by not counting them as a syllable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "880dae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count_per_word(words):\n",
    "    vowels = 'aeiouy'\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if word[0] in vowels:\n",
    "            count += 1\n",
    "        for index in range(1, len(word)):\n",
    "            if word[index] in vowels and word[index-1] not in vowels:\n",
    "                count += 1\n",
    "        if word.endswith('es' or 'ed'):\n",
    "            count -= 1\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "    return count / len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2b102a",
   "metadata": {},
   "source": [
    "### Personal Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f862047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_personal_pronouns(text):\n",
    "    pattern = r'\\b(I|we|my|ours|he|she|us|him|they|them)\\b'\n",
    "    return len(re.findall(pattern, text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f55fd",
   "metadata": {},
   "source": [
    "### Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14231cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_length(words):\n",
    "    word_length = 0\n",
    "    for word in words:\n",
    "        word_length = word_length + len(word)\n",
    "        \n",
    "    return word_length / len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b090b0",
   "metadata": {},
   "source": [
    "# Calculating Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f335386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_variables(text):\n",
    "    cleaned_text = clean_text(text)\n",
    "    words = remove_stopwords(cleaned_text)\n",
    "    \n",
    "    pos_score = positive_score(words)\n",
    "    neg_score = negative_score(words)\n",
    "    pol_score = polarity_score(pos_score, neg_score)\n",
    "    sub_score = subjectivity_score(pos_score, neg_score, words)\n",
    "    \n",
    "    sent_len = avg_sent_len(cleaned_text, words)\n",
    "    p_comp_words = percentage_of_comp_words(words)\n",
    "    fog_ind = fog_index(sent_len, p_comp_words)\n",
    "    \n",
    "    comp_words = complex_words(words)\n",
    "    counts = word_counts(words)\n",
    "    avg_syllable_per_word = syllable_count_per_word(words)\n",
    "    personal_pronouns = count_personal_pronouns(cleaned_text)\n",
    "    word_len = avg_word_length(words)\n",
    "    \n",
    "    variables = [pos_score, neg_score, pol_score, sub_score, sent_len, p_comp_words, fog_ind, comp_words, counts, avg_syllable_per_word, personal_pronouns, word_len]\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "859a5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\gowda\\Jupiter Projects\\reviews.csv')\n",
    "\n",
    "header = ['POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', 'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX', 'COMPLEX WORD COUNT', 'WORD COUNT', 'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH']\n",
    "root_path = 'Articles'\n",
    "\n",
    "csv_file = open('rev.csv', 'a', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow(header)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "for review in data['desciption']:\n",
    "    try:\n",
    "        variables = extract_variables(review)\n",
    "        csv_writer.writerow(variables)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "csv_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
